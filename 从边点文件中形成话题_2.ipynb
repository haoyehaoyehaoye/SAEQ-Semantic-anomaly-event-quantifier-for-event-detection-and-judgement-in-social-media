{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\py311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community #  \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from networkx.algorithms.community.quality import modularity\n",
    "import random\n",
    "import wikipediaapi\n",
    "from keybert import KeyBERT\n",
    "import time\n",
    "from gensim import models,corpora\n",
    "from math import log, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadTweetsByTime(dataname,date):\n",
    "    doclist=[]\n",
    "    if dataname=='GPT': #搜集的推特关于GPT的数据集，时间从一月四号持续到三月29号\n",
    "       with open('../推特GPT/GPT.csv',encoding=\"utf-8\") as f:\n",
    "         f_csv = csv.reader(f)\n",
    "         pos = 1\n",
    "         for row in f_csv:\n",
    "            if  len(row)>=6:  #控制聚类文本数目并处理缺失数据,全部跑太多了跑不了\n",
    "                #print(row[0][:10])  #取到日期\n",
    "                if row[0][:10] == date: #判断时间\n",
    "                    #print(row[0])\n",
    "                    doclist.append(row[2])\n",
    "                    pos+=1\n",
    "         print(f'总数量{pos}')\n",
    "    #return random.sample(doclist,200)\n",
    "    global data_number\n",
    "    if data_number!=0:\n",
    "        return random.sample(doclist,data_number)\n",
    "    else:  #表示数据全部要\n",
    "        data_number=len(doclist)\n",
    "        return doclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#工具函数算边\n",
    "def GetBrim(list_word):\n",
    "    #获取节点间的边信息，主要使用相似度\n",
    "    list_link_dic=[]\n",
    "    global threshold_similarity  #全局变量，边的门限\n",
    "    model = models.word2vec.Word2Vec.load('word2vec.model')  #使用相似度试试\n",
    "    for i in range(0,len(list_word)):\n",
    "        dic={}\n",
    "        for j in range(i+1,len(list_word)):\n",
    "            try:\n",
    "               similarity = model.wv.similarity(list_word[i],list_word[j])\n",
    "            except:\n",
    "               similarity=0   #主要是不存在某个词的情况\n",
    "            if(similarity>=threshold_similarity):  #判断点的权重\n",
    "                dic={}\n",
    "                dic['Source']=i\n",
    "                dic['Target']=j\n",
    "                dic['Type']=0\n",
    "                dic['Weight']=similarity\n",
    "                list_link_dic.append(dic)\n",
    "        #print(f\"\\r算边中:{(i+1)/len(list_word)}\",end=' ')\n",
    "        print(\"\\r\", end=\"\")\n",
    "        print(f'算边进度为{(i+1)/len(list_word)}',end=\"\",flush=True)\n",
    "    print('\\n完成算边')\n",
    "    return list_link_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetKeyBertWord(dataname,date):\n",
    "    #使用keybert方法，获取关键词\n",
    "    kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "    doclist=ReadTweetsByTime(dataname,date)\n",
    "    dic={}\n",
    "    list_word=[]\n",
    "    list_weight=[]\n",
    "    pos=0\n",
    "    for item in doclist:\n",
    "        #print(item)\n",
    "        pos=pos+1\n",
    "        global data_number\n",
    "        #print(pos/data_number)\n",
    "        print(\"\\r\", end=\"\")\n",
    "        print(\"取词中: {}\".format(pos/data_number),end=\"\") #进度条\n",
    "        #有点慢，两千条数据要跑十分钟\n",
    "        keywords_phrase = kw_model.extract_keywords(item, \n",
    "                                     keyphrase_ngram_range=(1,1),   #这个就是范围,可以考虑词组,本实验暂时只考虑词\n",
    "                                     stop_words='english', \n",
    "                                     highlight=False, \n",
    "                                     top_n=3) \n",
    "        keywords_phrase_list= list(keywords_phrase)#结果，返回的是列表包含元组的形式[(),()]\n",
    "        #print(keywords_phrase_list)\n",
    "        \n",
    "        for word in keywords_phrase_list:\n",
    "            #print(word[0])\n",
    "            #把数据加入字典,要处理1.去除全局的词  2.判断是否已经存在于字典中\n",
    "            if word[0] not in ['chatgpt','gpt','#chatgpt','chat']:\n",
    "              if word[0] not in list_word:\n",
    "                list_word.append(word[0])\n",
    "                list_weight.append(word[1])\n",
    "              else:\n",
    "                index=list_word.index(word[0])\n",
    "                list_weight[index]=list_weight[index]+word[1]\n",
    "        #print(keywords_list)\n",
    "        \n",
    "    #最终返回两个数据，字典形式的结果和原始数据\n",
    "    dic['word']=list_word\n",
    "    dic['weight']=list_weight\n",
    "    print(' ')#这个空行主要是为了和进度条配合完成换行,后面也有\n",
    "    return dic,doclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadNodeAndList(file):\n",
    "    #从文件中读取节点和边\n",
    "    list_node=[]\n",
    "    list_link=[]\n",
    "    list_node_label=[]\n",
    "    list_size=[]\n",
    "    file_node=file+'-node.csv'\n",
    "    with open(file_node, encoding=\"UTF8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header_row = next(reader)\n",
    "        for row in reader:\n",
    "            #print(row)\n",
    "            list_node.append(row[0])\n",
    "            list_node_label.append(row[1])\n",
    "            list_size.append(row[4])\n",
    "    file_link=file+'-link.csv'\n",
    "    with open(file_link, encoding=\"UTF8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header_row = next(reader)\n",
    "        for row in reader:\n",
    "            #print(row)\n",
    "            tuple=(row[0],row[1],eval(row[3])) #依次为source target weight  注意是无向的\n",
    "            #print(type(eval(row[3])))    #要转数字形式\n",
    "            list_link.append(tuple)\n",
    "    return list_node,list_link,list_node_label,list_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeLabel(list_word):\n",
    "    #获得话题的label，方法为从wiki搜索指定几个关键词的网页并解析，然后选取最关键词\n",
    "    #注意连vpn\n",
    "    #user_agent需要时常修改\n",
    "    kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 Edg/117.0.2045.60'\n",
    "    #print('成功加载模型')\n",
    "    def get_word_background(word):\n",
    "        wiki = wikipediaapi.Wikipedia(language='en',user_agent=user_agent)\n",
    "        page = wiki.page(word)\n",
    "        if page.exists():\n",
    "            return page.summary\n",
    "        else:\n",
    "            return ''\n",
    "    page_source=''\n",
    "    for item in list_word:\n",
    "        page_source = page_source+get_word_background(item)\n",
    "    keywords_phrase = kw_model.extract_keywords(page_source, \n",
    "                                     keyphrase_ngram_range=(1,1),   #这个就是范围,可以考虑词组\n",
    "                                     stop_words='english', \n",
    "                                     highlight=False, \n",
    "                                     top_n=1) \n",
    "    keywords_phrase_list= list(keywords_phrase)\n",
    "    for word in keywords_phrase_list:\n",
    "        return word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTypeNode(filename,list_dic):\n",
    "    #生成带type和typelabel的csv文件\n",
    "    #这一步主要是为了gephi画图。  在gephi中打开node_type和link即可\n",
    "    filename=filename+'-node_type.csv'\n",
    "    with open(filename, 'w', encoding='UTF8',newline=\"\") as f_link:\n",
    "        writer = csv.DictWriter(f_link,fieldnames=['id','label','size','type','typelabel']) \n",
    "        writer.writeheader()\n",
    "        for item in list_dic:\n",
    "            writer.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGNAndOption(file,seed):\n",
    "    #利用network的\n",
    "    fig = plt.figure(figsize=(100, 80))   #要在一开始调整图片大小，不然无法显示\n",
    "    list_node,list_link,list_node_label,list_size=ReadNodeAndList(file)\n",
    "    list_dic=[]\n",
    "    #生成一个字典，后续还要更新就不放在其他函数里面了\n",
    "    for i in range(len(list_node)):\n",
    "        dic={}\n",
    "        dic['id']=list_node[i]\n",
    "        dic['label']=list_node_label[i]\n",
    "        dic['size']=list_size[i]\n",
    "        list_dic.append(dic)    \n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(list_node)            #使用列表添加节点，但是如果要带其他属性则不方便\n",
    "    G.add_weighted_edges_from(list_link)\n",
    "    communities = nx.algorithms.community.girvan_newman(G)\n",
    "    best_communities = None\n",
    "    best_modularity = -1\n",
    "    for community in communities: #获取最佳聚类结果\n",
    "        #print(community)\n",
    "        Q = modularity(G, community)  #用以衡量聚类效果的函数\n",
    "        if Q > best_modularity:\n",
    "            best_modularity = Q\n",
    "            best_communities = community\n",
    "        \n",
    "    list_community=[]  #存所有簇    \n",
    "    list_derail=[]  #存离群点\n",
    "    for i, community in enumerate(best_communities):\n",
    "        node=list(community)#字典转list\n",
    "        if len(community)==1:   #对于离群点\n",
    "            list_derail.append(node[0])\n",
    "        if len(community)<=3 and len(community)>1:   #对于小群\n",
    "            list_community.append(node)\n",
    "        if len(community)>3:\n",
    "            list_community.append(node)\n",
    "    list_community.append(list_derail)    #最后一个一定是离群点集合    \n",
    "    #print(list_community)\n",
    "    list_typelabel=[]\n",
    "    for type in range(len(list_community)):\n",
    "        list_word=[]\n",
    "        for item in list_community[type]:\n",
    "            for index, word in enumerate(list_dic):  #找到对应id的label\n",
    "                if word['id'] == item:\n",
    "                  #print(word)\n",
    "                  list_word.append(word['label'])\n",
    "        #一个type得到一个标签\n",
    "        typelabel=typeLabel(list_word)\n",
    "        time.sleep(6)\n",
    "        list_typelabel.append(typelabel)\n",
    "    #装载如原字典\n",
    "    for type in range(len(list_community)):    \n",
    "        for item in list_community[type]:\n",
    "            for index, word in enumerate(list_dic):  #找到对应id的label\n",
    "                if word['id'] == item:\n",
    "                  word['type']=type\n",
    "                  word['typelabel']=list_typelabel[type]\n",
    "    #for item in list_dic:\n",
    "    #    print(item)\n",
    "    return list_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judgementWordInTopic(word,topic_exist):\n",
    "    #本函数用以判断一个词是否已经存在于一个存在的话题中了\n",
    "    #会人为的赋予一些经验和修正\n",
    "    if(word=='elon' or word=='musk'):\n",
    "        word='elonmusk'\n",
    "    if(word in topic_exist):\n",
    "        return 1\n",
    "    if(word not in topic_exist):\n",
    "        return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeTopic(list_all_topics,time_list):\n",
    "    #合并各日期的话题\n",
    "    #此函数得到的是一个全局性的总话题\n",
    "    list_merge_topics=[]  #形如[[话题1单词],[话题2单词]]\n",
    "    threshold=0.6       #合并话题的阈值\n",
    "    for pos_day in range(len(list_all_topics)):\n",
    "        #dic_merge_topics={}\n",
    "        #dic_merge_topics['time']=time_list[pos_day]\n",
    "        if(pos_day==0):  #第一天的数据直接加入话题\n",
    "            for topic in list_all_topics[pos_day]:\n",
    "                #print(topic)\n",
    "                topic=topic['topic_word_list']  #只取话题中的词即可\n",
    "                list_merge_topics.append(topic)\n",
    "        else:\n",
    "            for topic in list_all_topics[pos_day]:\n",
    "                topic=topic['topic_word_list']  #只取话题中的词即可\n",
    "                flag=0\n",
    "                for topic_exist in list_merge_topics: #遍历已经存在的话题\n",
    "                    count=0  #计数,若对于某一个已存在话题有多于百分之X的重合则视为同一个话题\n",
    "                    for word in topic:\n",
    "                        if judgementWordInTopic(word,topic_exist):\n",
    "                            count+=1\n",
    "                            flag=1\n",
    "                    if(count/len(topic)>threshold):  #大于阈值则更新那一个\n",
    "                        count_update_word=0  #更新词的pos\n",
    "                        for word in topic:\n",
    "                            if(judgementWordInTopic(word,topic_exist)==0):\n",
    "                                topic_exist.append(word)\n",
    "                                count_update_word+=1\n",
    "                            if(count_update_word>2):  #只存前三个词\n",
    "                                break\n",
    "                        break                         \n",
    "                if(flag==0):#表示作为一个新的话题\n",
    "                    list_merge_topics.append(topic)\n",
    "                    print('新话题')\n",
    "    #for item in list_merge_topics:\n",
    "    #    print(item)\n",
    "    #到这一步 list_merge_topics已经完成了\n",
    "    #之后包装一下，每个topics成字典   [[{代表词，序号,词}],[代表词，序号,词]]\n",
    "    list_dic_merge_topics=[]\n",
    "    for item in list_merge_topics:                 \n",
    "         dic={}\n",
    "         dic['type']=list_merge_topics.index(item)\n",
    "         dic['word']=item\n",
    "         dic['typelabel']=typeLabel(item)\n",
    "         list_dic_merge_topics.append(dic)\n",
    "    print(list_dic_merge_topics)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordAccept(words,list_exist_all_topics,index,type):\n",
    "    #用来判断本日的话题更新之后有哪些词\n",
    "    global step\n",
    "    words_add=[]\n",
    "    if index<step:\n",
    "        #在最开始的几天\n",
    "        words_exist=[]\n",
    "        for i in range (0,index):  #倒挡，把之前同一个话题的都加入\n",
    "            for topic_exist in list_exist_all_topics[i]:\n",
    "                if(topic_exist['type']==type):\n",
    "                    words_exist+=topic_exist['word']\n",
    "        words_add = words + [x for x in words if x not in words_exist]\n",
    "        return words_add\n",
    "    else:\n",
    "        #最近一天的加入前70%,然后减半\n",
    "        words_add=[]\n",
    "        for i in range (1,step+1):  #倒挡，按比例把之前的加入\n",
    "            for topic_exist in list_exist_all_topics[index-i]:\n",
    "                if(topic_exist['type']==type):\n",
    "                    length=int(len(topic_exist['word'])/(0.6/(2**index)))\n",
    "                    #print(topic_exist['word'])\n",
    "                    words_add+=topic_exist['word'][:length]  #顺序会被打乱\n",
    "        words_add=words_add+words\n",
    "        return list(set(words_add))     #去重后返回        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicateRemovalType(list_exist):\n",
    "    type_set = set()\n",
    "    list_get=[]\n",
    "    for item  in list_exist:\n",
    "        if item['type'] not in type_set:  # 如果type没有出现过，则将其添加到type_set集合中\n",
    "            type_set.add(item['type'])\n",
    "            list_get.append(item)\n",
    "        else:  # 如果type已经出现过，则找到之前的元素并进行合并\n",
    "            for prev_item in list_get:\n",
    "                if prev_item['type'] == item['type']:\n",
    "                    prev_item['word']=prev_item['word']+item['word']\n",
    "                    prev_item['word']=list(set(prev_item['word'])) \n",
    "                    break\n",
    "    return list_get                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeAndMinusTopic(list_alldays_topic,time_list):\n",
    "    #合并各日期的topic,并且要求做到日期更新\n",
    "    #输入的参数见getTopicChange\n",
    "    list_exist_all_topics=[]   #里面每个list是一组（一组就是三天）的，每一组的中有数个{},每个{}表示一个话题的信息\n",
    "    threshold=0.7\n",
    "    type_max=0    #标记最靠后的一个type，比这个大的就是没有的topic\n",
    "    #第一步，初始化一个话题。离群点已经去除\n",
    "    list_exist=[]  #中间变量，某一组的话题\n",
    "    for topic in list_alldays_topic[0]:   #把第一天的当成\n",
    "        #print(topic)\n",
    "        dic={}\n",
    "        dic['type']=list_alldays_topic[0].index(topic)   #标记话题\n",
    "        dic['word']=topic['topic_word_list']  #取话题中的词\n",
    "        dic['time']=time_list[0]\n",
    "        dic['size']=topic['size']\n",
    "        type_max=dic['type']\n",
    "        list_exist.append(dic)\n",
    "    list_exist_all_topics.append(list_exist)\n",
    "    #将之后的组更新入\n",
    "    for index in range(1,len(time_list)):\n",
    "        list_exist=[]\n",
    "        print(time_list[index])\n",
    "        for topic in list_alldays_topic[index]:\n",
    "            words=topic['topic_word_list']\n",
    "            flag=0  #用来标记新话题\n",
    "            #print(words)\n",
    "            for topic_exist in list_exist_all_topics[index-1]:  #倒退一组数据比话题,每个topic_exist是一个字典\n",
    "                    count=0  #计数,若对于某一个已存在话题有多于百分之X的重合则视为同一个话题\n",
    "                    for word in words:\n",
    "                        count+=judgementWordInTopic(word,topic_exist['word'])  #在其中会返回1，不然就是返回0\n",
    "                    if((count/len(words))>threshold):    #有一种可能情况时，两个子话题属于同一个已经存在的话题，要进行处理\n",
    "                        flag=1  #表明不是新话题\n",
    "                        dic={}\n",
    "                        dic['type']=topic_exist['type']  #一样的话题就有一样的type\n",
    "                        words_add=wordAccept(words,list_exist_all_topics,index,dic['type'])\n",
    "                        dic['word']=words_add              #话题本次更新的词\n",
    "                        dic['time']=time_list[index]\n",
    "                        dic['size']=topic['size']\n",
    "                        list_exist.append(dic)  \n",
    "            if(flag==0):#表示作为一个新的话题\n",
    "                dic={}\n",
    "                type_max+=1\n",
    "                dic['type']=type_max\n",
    "                dic['word']=words\n",
    "                dic['time']=time_list[index]\n",
    "                dic['size']=topic['size']\n",
    "                list_exist.append(dic)\n",
    "        #有可能一个type出现两次，这里要进行合并。  之所以不在添加的时候判断，主要是为了节省运行时间\n",
    "        list_exist = duplicateRemovalType(list_exist)\n",
    "        list_exist_all_topics.append(list_exist)\n",
    "    for topics in list_exist_all_topics:\n",
    "        for topic in topics:\n",
    "            print(topic)\n",
    "    return   list_exist_all_topics\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicChange(file_list):\n",
    "    #用这个函数把之前所有的node_type文件写入一个包含各个节点信息的csv\n",
    "    #获取各日期type的改变\n",
    "    #之后会调用merge合并各日期的话题\n",
    "    list_all=[]\n",
    "    #把所有的文件读取出来\n",
    "    for file in file_list:\n",
    "        list_file=[]\n",
    "        with open(file+'-node_type.csv','r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                # 处理每行数据\n",
    "                dic={}\n",
    "                dic['label']=row[1]\n",
    "                dic['size']=row[2]\n",
    "                dic['type']=eval(row[3])\n",
    "                dic['typelabel']=row[4]\n",
    "                list_file.append(dic)\n",
    "        list_all.append(list_file)  \n",
    "    list_alldays_topic=[]\n",
    "    for list_file in list_all:\n",
    "        #print(list_file)\n",
    "        list_topic=[]\n",
    "        derail_topic = 0\n",
    "        #找到离群的话题，去除\n",
    "        for item in list_file:\n",
    "            if(item['type']>derail_topic):\n",
    "                derail_topic = item['type']\n",
    "        #print(derail_topic)\n",
    "        for item in list_file:\n",
    "            #对于每一段时间的节点而言\n",
    "            #print(item)\n",
    "            if(item['type']!=derail_topic):\n",
    "              if (judgementTypelabel(item['typelabel'],list_topic)==1): #判断字典中是否存在\n",
    "                #存在则修改 \n",
    "                for topic in list_topic:\n",
    "                    if(topic['typelabel']==item['typelabel']):\n",
    "                        topic['size']=topic['size']+eval(item['size'])  #更新权重\n",
    "                        topic['topic_word_list'].append(item['label']) #更新词表\n",
    "              else:\n",
    "                 #不存在则加入\n",
    "                dic={}\n",
    "                dic['typelabel']=item['typelabel']\n",
    "                dic['size']=eval(item['size'])\n",
    "                dic['topic_word_list']=[item['label']]\n",
    "                list_topic.append(dic)\n",
    "        list_alldays_topic.append(list_topic)  #加入总的话题list\n",
    "    #for topic in list_alldays_topic:\n",
    "    #    print(file_list[list_alldays_topic.index(topic)])\n",
    "    #    for item in topic:\n",
    "    #        print(item)\n",
    "    #list_alldays_topic中每个topic存储样式为\n",
    "    #{'typelabel': 'openai', 'size': 2425.2642000000014, 'topic_word_list': ['ai', 'openai', 'microsoft', 'google', 'bing', 'bot', 'gpt3', 'msft', 'app', 'robot', 'siri']}\n",
    "    #{'typelabel': 'chatbots', 'size': 525.2162000000001, 'topic_word_list': ['chatbot', 'chatbots', 'generative', 'language', 'technology', 'intelligence', 'bots']}\n",
    "    #下面需要的是，整理合并具有相似内容的\n",
    "    global time_list\n",
    "    #MergeTopic(list_alldays_topic,time_list) \n",
    "    list_exist_all_topics = mergeAndMinusTopic(list_alldays_topic,time_list)\n",
    "    return list_exist_all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judgementTypelabel(str,list_topic):\n",
    "    #这个函数用来判断str(即typelabel)是否已经在字典中存在\n",
    "    flag=0\n",
    "    #print(list_topic)\n",
    "    for dic in list_topic:\n",
    "        if dic['typelabel']==str:\n",
    "            flag=1\n",
    "    return flag        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pictureGephi(file_list,seed):\n",
    "    #这个函数的作用是获取聚类结果并写入gephi所需的csv方便画图\n",
    "    #只需要运行一次即可\n",
    "    for file in file_list:\n",
    "        list_dic=getGNAndOption(file,seed)\n",
    "        writeTypeNode(file,list_dic)\n",
    "        print('完成了一个')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPointwiseMutualValue(word_1,word_2,doclist):\n",
    "    value_1=0\n",
    "    value_2=0\n",
    "    value_mutual=0\n",
    "    count_word=0  #一共出现多少词\n",
    "    for item in doclist:\n",
    "        if word_1 in item: value_1+=1\n",
    "        if word_2 in item: value_2+=1\n",
    "        if word_1 in item and word_2 in item: value_mutual+=1\n",
    "        count_word=count_word+item.count(' ')+1 #用空格作为分词的依据\n",
    "    return value_1/count_word,value_2/count_word,value_mutual/count_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTopic(todays_word,todays_weight,topics):\n",
    "    ls_word=[]\n",
    "    composition_number=1.66  #一个超参数,表示传入的话题数据需扩大多少。比如如果是一天的数据，在V3中（一组）就应该扩大3，若为两天的数据则应该扩大1.5\n",
    "    model = models.word2vec.Word2Vec.load('word2vec.model')\n",
    "    for word in todays_word:\n",
    "        flag=0\n",
    "        for topic in topics:\n",
    "            if(word in topic['word']):\n",
    "                flag=1\n",
    "        if(flag==0):\n",
    "            ls_word.append(word)\n",
    "    #print(ls_word)                 #ls_word即为没有直接存在某一个话题中\n",
    "    #1.首先，看看有没有可能的新话题生成\n",
    "    list_newtopic=[]\n",
    "    for i in range(len(ls_word)):\n",
    "        for j in range(i,len(ls_word)):\n",
    "            flag=0\n",
    "            if(ls_word[i] !=ls_word[j]):\n",
    "                    try:\n",
    "                       similarity = model.wv.similarity(ls_word[i],ls_word[j])\n",
    "                    except:\n",
    "                       similarity=0   #主要是不存在某个词的情况\n",
    "                    if(similarity>0.8):\n",
    "                        if(len(list_newtopic)>0):\n",
    "                            for item in list_newtopic:   #将新话题加入\n",
    "                                if(ls_word[i] in item or ls_word[j] in item):\n",
    "                                    item.append(ls_word[i])\n",
    "                                    item.append(ls_word[j])\n",
    "                                    item = list(set(item))\n",
    "                                    flag=1\n",
    "                        if(flag==0):\n",
    "                            ls=[]\n",
    "                            ls.append(ls_word[i])\n",
    "                            ls.append(ls_word[j])        \n",
    "                            list_newtopic.append(ls)\n",
    "    #print(list_newtopic)\n",
    "    \n",
    "                            \n",
    "    #2.然后，看看已有话题的影响\n",
    "    baseline=0  #2.1计算每个topic的基准影响值，人话就是计算本来存在的话题本身单词的pmi均值,没用这个变量，直接算就行了。  放个变量只是为了表示有这么个东西\n",
    "    for topic in topics:\n",
    "        pos=0\n",
    "        value_pmi_sum=0\n",
    "        for i in range(len(topic['word'])):\n",
    "            for j in range(i+1,len(topic['word'])):\n",
    "                value_i,value_j,value_mutual=GetPointwiseMutualValue(topic['word'][i],topic['word'][j],doclist)\n",
    "                if value_mutual != 0:\n",
    "                    value_pmi=log((value_mutual/(value_i*value_j)),2)\n",
    "                else:\n",
    "                    value_pmi=0 \n",
    "                if(value_pmi):    #话题增益\n",
    "                    pos+=1\n",
    "                    value_pmi_sum+=value_pmi\n",
    "                    #print(topic['word'][i],topic['word'][j],value_pmi)\n",
    "        if(pos!=0):            \n",
    "            topic['pmi_baseline']= value_pmi_sum/pos\n",
    "        else:\n",
    "            topic['pmi_baseline']=0    \n",
    "        #2.2计算未出现的词与话题的pmi   \n",
    "    list_pmi=[]\n",
    "    for word in ls_word:\n",
    "        for topic in topics:\n",
    "            pos=0\n",
    "            value_pmi_sum=0\n",
    "            #print(topic['pmi_baseline'])    \n",
    "            for topic_word in topic['word']:\n",
    "                value_i,value_j,value_mutual=GetPointwiseMutualValue(word,topic_word,doclist)\n",
    "                if value_mutual != 0:\n",
    "                    value_pmi=log((value_mutual/(value_i*value_j)),2)\n",
    "                else:\n",
    "                    value_pmi=0 \n",
    "                if(value_pmi):    #话题增益\n",
    "                        #print(word,topic['type'],value_pmi)\n",
    "                        pos+=1\n",
    "                        value_pmi_sum+=value_pmi\n",
    "            if(pos>0):  #对于已经有增益的词            \n",
    "                if((value_pmi_sum/pos)>topic['pmi_baseline']):        \n",
    "                    dic={}\n",
    "                    dic['word']=word\n",
    "                    dic['type']=topic['type']\n",
    "                    dic['pmi']=value_pmi_sum/pos\n",
    "                    #print(dic)\n",
    "                    list_pmi.append(dic)\n",
    "    #print(list_pmi)\n",
    "    #3. 计算新话题的PMI\n",
    "    #具体计算\n",
    "    for newtopic in list_newtopic:\n",
    "        for i in range(len(newtopic)):\n",
    "            for j in range(i+1,len(newtopic)): \n",
    "                #print(newtopic[i],newtopic[j])\n",
    "                value_i,value_j,value_mutual=GetPointwiseMutualValue(newtopic[i],newtopic[j],doclist)\n",
    "                if value_mutual != 0:\n",
    "                    value_pmi=log((value_mutual/(value_i*value_j)),2)\n",
    "                else:\n",
    "                    value_pmi=0\n",
    "                if(value_pmi): \n",
    "                    #print(newtopic[i],newtopic[j],value_pmi)          #暂时没想好怎么用\n",
    "                    continue\n",
    "    #3.1  看是否需要将新词加入\n",
    "    #方法为计算一个不存在在某个话题中的词与话题中的词的相似度，有两个超过阈值的则加入\n",
    "    for topic in topics:\n",
    "        for word in ls_word:\n",
    "            flag=0  #每个单词计算\n",
    "            for topic_word in topic['word']:\n",
    "                    try:\n",
    "                       similarity = model.wv.similarity(word,topic_word)\n",
    "                    except:\n",
    "                       similarity=0   #主要是不存在某个词的情况\n",
    "                    if(similarity>0.8):\n",
    "                        flag+=1\n",
    "            if(flag>=2):\n",
    "                topic['word'].append(word)                           \n",
    "                    \n",
    "    #4.获取已有话题减益并归纳上面的结果\n",
    "    result_get={}  #\n",
    "    result_get['old_topic']=[]\n",
    "    result_get['new_topic']=[]\n",
    "    for topic in topics:\n",
    "        dic={}\n",
    "        now_size=0\n",
    "        dic['type']=topic['type']\n",
    "        for topic_word in topic['word']:\n",
    "            if(topic_word in todays_word):\n",
    "                  now_size=now_size+todays_weight[todays_word.index(topic_word)]\n",
    "        if(now_size*composition_number>topic['size']*1.2):  #随便设一个超参数\n",
    "            dic['change']='上升'\n",
    "        if(now_size*composition_number<topic['size']*1.2 and now_size*composition_number>topic['size']*0.8):  #随便设一个超参数\n",
    "            dic['change']='相对稳定'\n",
    "        if(now_size*composition_number<topic['size']*0.8):  #随便设一个超参数\n",
    "            dic['change']='下降'                  \n",
    "        dic['word']=topic['word']\n",
    "        dic['pre_size']=now_size*composition_number\n",
    "        dic['time']=topic['time']\n",
    "        dic['influence_word']=[]   #被影响的词\n",
    "        for item in  list_pmi:\n",
    "            if(item['type']==dic['type']):\n",
    "                dic['influence_word'].append(item['word'])\n",
    "        result_get['old_topic'].append(dic)                 \n",
    "       # print(f\"上一步size:{topic['size']},本次size:{now_size*3}\")           \n",
    "    result_get['new_topic']=list_newtopic        #不仅是新话题的出现 还要考虑新话题的排序   \n",
    "    #for item in result_get['old_topic']:\n",
    "    #    print(item)    \n",
    "    #最终参数\n",
    "    #list_pmi是本次新出现单词与以往type的影响\n",
    "    #list_newtopic是获取的可能新话题\n",
    "    #result_get是最终的结果，里面有两个属性，第一个属性是旧有话题的变化，第二个属性是新话题的产生\n",
    "    return result_get\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V3文件 2月5日前有一些小问题，就是数据经过了抽样（只取了11000多条数据，对实验结果影响不大。  暂时不改了\n",
    "file_list=[\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月6日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月9日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月12日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月15日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月18日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月21日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月24日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月27日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/1月30日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月2日起11728全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月5日起22806全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月8日起24368全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月11日起17814全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月14日起18673全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月17日起16115全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月20日起17954全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月23日起15076全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/2月26日起13956全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月1日起17547全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月4日起13555全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月7日起15353全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月10日起12912全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月13日起25126全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月16日起25263全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月19日起20431全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月22日起24489全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月25日起19776全数据，边为相似度,门限0.8',\n",
    "    'E:\\code\\舆情idea2\\推特GPT\\成图csvV3/3月28日起16429全数据，边为相似度,门限0.8',\n",
    "]\n",
    "time_list=[\n",
    "    '1/6','1/9','1/12','1/15','1/18','1/21','1/24','1/27','1/30','2/2','2/5','2/8','2/11','2/14','2/17','2/20','2/23','2/26','3/1','3/4','3/7','3/10','3/13','3/16','3/19','3/22','3/25','3/28'\n",
    "]\n",
    "seed=1234\n",
    "random.seed(seed)\n",
    "step=2  #日期更新词的时候回顾的天数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9\n",
      "1/12\n",
      "1/15\n",
      "1/18\n",
      "1/21\n",
      "1/24\n",
      "1/27\n",
      "1/30\n",
      "2/2\n",
      "2/5\n",
      "2/8\n",
      "2/11\n",
      "2/14\n",
      "2/17\n",
      "2/20\n",
      "2/23\n",
      "2/26\n",
      "3/1\n",
      "3/4\n",
      "3/7\n",
      "3/10\n",
      "3/13\n",
      "3/16\n",
      "3/19\n",
      "3/22\n",
      "3/25\n",
      "3/28\n",
      "{'type': 0, 'word': ['ai', 'openai', 'google', 'bing', 'microsoft', 'bot', 'gpt3', 'search'], 'time': '1/6', 'size': 1603.256100000001}\n",
      "{'type': 1, 'word': ['chatbot', 'chatbots', 'language', 'generative', 'intelligence', 'technology'], 'time': '1/6', 'size': 362.46159999999986}\n",
      "{'type': 2, 'word': ['chatgpt3', 'prompts', 'tweet', 'text', 'tweets', 'code', 'nlp'], 'time': '1/6', 'size': 200.7716}\n",
      "{'type': 3, 'word': ['seo', 'content'], 'time': '1/6', 'size': 57.10700000000001}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/6', 'size': 82.14900000000002}\n",
      "{'type': 0, 'word': ['ai', 'openai', 'microsoft', 'google', 'bing', 'bot', 'gpt3', 'app', 'robot', 'app', 'robot'], 'time': '1/9', 'size': 1883.8482}\n",
      "{'type': 1, 'word': ['chatbot', 'chatbots', 'generative', 'language', 'technology', 'intelligence'], 'time': '1/9', 'size': 316.4374999999999}\n",
      "{'type': 5, 'word': ['chatgpt3', 'msft', 'nlp', 'text', 'prompts', 'https', 'elonmusk', 'code'], 'time': '1/9', 'size': 211.5415}\n",
      "{'type': 6, 'word': ['writing', 'essays', 'essay'], 'time': '1/9', 'size': 78.1586}\n",
      "{'type': 7, 'word': ['marketing', 'business'], 'time': '1/9', 'size': 48.08240000000001}\n",
      "{'type': 4, 'word': ['students', 'teachers'], 'time': '1/9', 'size': 43.4782}\n",
      "{'type': 0, 'word': ['gpt3', 'bot', 'ai', 'app', 'robot', 'search', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/12', 'size': 1570.5742000000014}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/12', 'size': 306.8595999999999}\n",
      "{'type': 8, 'word': ['writing', 'essays', 'essay', 'education', 'teaching'], 'time': '1/12', 'size': 127.84559999999999}\n",
      "{'type': 5, 'word': ['nlp', 'text', 'chatgpt3', 'code', 'elonmusk', 'msft', 'chatgpt4', 'prompts', 'https'], 'time': '1/12', 'size': 118.41250000000001}\n",
      "{'type': 9, 'word': ['prompts', 'text', 'tweet', 'tweets', 'code'], 'time': '1/12', 'size': 116.15810000000002}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/12', 'size': 54.170300000000005}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'robot', 'search', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/15', 'size': 1650.7189999999996}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/15', 'size': 366.32140000000004}\n",
      "{'type': 8, 'word': ['education', 'teaching', 'essays', 'writing', 'essay'], 'time': '1/15', 'size': 66.39440000000002}\n",
      "{'type': 5, 'word': ['nlp', 'text', 'chatgpt3', 'code', 'elonmusk', 'msft', 'chatgpt4', 'prompts', 'https'], 'time': '1/15', 'size': 101.60480000000001}\n",
      "{'type': 10, 'word': ['seo', 'marketing', 'business', 'content'], 'time': '1/15', 'size': 102.3063}\n",
      "{'type': 11, 'word': ['song', 'tweet', 'poem'], 'time': '1/15', 'size': 67.5178}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/15', 'size': 53.741799999999984}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'robot', 'search', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/18', 'size': 1702.4551}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/18', 'size': 349.8528}\n",
      "{'type': 10, 'word': ['seo', 'business', 'marketing', 'content'], 'time': '1/18', 'size': 86.0529}\n",
      "{'type': 5, 'word': ['nlp', 'text', 'chatgpt3', 'code', 'elonmusk', 'msft', 'chatgpt4', 'prompts', 'https'], 'time': '1/18', 'size': 97.13019999999999}\n",
      "{'type': 12, 'word': ['prompts', 'text', 'prompt'], 'time': '1/18', 'size': 76.55169999999998}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/18', 'size': 49.63000000000001}\n",
      "{'type': 11, 'word': ['song', 'tweet', 'poem'], 'time': '1/18', 'size': 44.2444}\n",
      "{'type': 13, 'word': ['crypto', 'binance', 'stocks', 'bitcoin', 'layoffs'], 'time': '1/18', 'size': 112.3345}\n",
      "{'type': 14, 'word': ['podcast', 'blog'], 'time': '1/18', 'size': 38.2339}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'api', 'robot', 'search', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/21', 'size': 1472.487999999998}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/21', 'size': 346.8933}\n",
      "{'type': 15, 'word': ['microsoft', 'google', 'chatgpt3', 'mba', 'exam', 'msft', 'nlp', 'https'], 'time': '1/21', 'size': 465.0453000000001}\n",
      "{'type': 13, 'word': ['stocks', 'binance', 'layoffs', 'crypto', 'bitcoin'], 'time': '1/21', 'size': 154.92600000000002}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/21', 'size': 46.1112}\n",
      "{'type': 16, 'word': ['prompts', 'text', 'tweet', 'prompt', 'tweets'], 'time': '1/21', 'size': 106.96289999999998}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'gpt4', 'robot', 'search', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '1/24', 'size': 1732.8550999999998}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/24', 'size': 349.2432000000001}\n",
      "{'type': 15, 'word': ['nlp', 'chatgpt3', 'mba', 'msft', 'exams', 'buzzfeed', 'google', 'https', 'microsoft', 'exam'], 'time': '1/24', 'size': 208.27710000000002}\n",
      "{'type': 17, 'word': ['seo', 'marketing', 'content', 'business'], 'time': '1/24', 'size': 107.9999}\n",
      "{'type': 16, 'word': ['text', 'tweet', 'tweets', 'prompts', 'prompt'], 'time': '1/24', 'size': 104.6243}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'api', 'robot', 'search', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/27', 'size': 1411.4276999999986}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/27', 'size': 288.42130000000003}\n",
      "{'type': 15, 'word': ['nlp', 'chatgpt3', 'elonmusk', 'mba', 'msft', 'exams', 'buzzfeed', 'google', 'https', 'microsoft', 'exam'], 'time': '1/27', 'size': 135.305}\n",
      "{'type': 18, 'word': ['text', 'nlp', 'prompt', 'prompts', 'code'], 'time': '1/27', 'size': 112.5309}\n",
      "{'type': 19, 'word': ['students', 'teachers'], 'time': '1/27', 'size': 43.9959}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'gpt4', 'robot', 'search', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '1/30', 'size': 1800.3766}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/30', 'size': 368.9661999999999}\n",
      "{'type': 20, 'word': ['artificialintelligence', 'baidu', 'chatgpt3', 'elonmusk', 'https', 'nlp'], 'time': '1/30', 'size': 312.9301999999998}\n",
      "{'type': 18, 'word': ['nlp', 'text', 'code', 'prompts', 'prompt'], 'time': '1/30', 'size': 86.79860000000002}\n",
      "{'type': 21, 'word': ['seo', 'writing', 'marketing', 'automation', 'content', 'programming'], 'time': '1/30', 'size': 147.6582}\n",
      "{'type': 22, 'word': ['twitter', 'gmail'], 'time': '1/30', 'size': 45.9057}\n",
      "{'type': 19, 'word': ['teachers', 'students'], 'time': '1/30', 'size': 45.77380000000001}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '2/2', 'size': 1824.8246000000001}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'language'], 'time': '2/2', 'size': 374.4281999999999}\n",
      "{'type': 23, 'word': ['bias', 'biased', 'woke', 'biden'], 'time': '2/2', 'size': 102.9074}\n",
      "{'type': 24, 'word': ['twitter', 'text', 'prompts', 'youtube', 'tiktok', 'code', 'tweets'], 'time': '2/2', 'size': 147.09240000000003}\n",
      "{'type': 25, 'word': ['marketing', 'business'], 'time': '2/2', 'size': 38.19749999999999}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'openai', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'bard'], 'time': '2/5', 'size': 5023.005699999998}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/5', 'size': 805.5671999999996}\n",
      "{'type': 26, 'word': ['artificialintelligence', 'elonmusk', 'chatgpt3', 'baidu', 'https'], 'time': '2/5', 'size': 516.9139000000006}\n",
      "{'type': 27, 'word': ['bias', 'woke', 'racist'], 'time': '2/5', 'size': 106.2553}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '2/8', 'size': 5410.132099999998}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/8', 'size': 882.8296999999995}\n",
      "{'type': 26, 'word': ['baidu', 'artificialintelligence', 'chatgpt3', 'elonmusk', 'https'], 'time': '2/8', 'size': 529.2777999999997}\n",
      "{'type': 28, 'word': ['search', 'browser'], 'time': '2/8', 'size': 103.64699999999999}\n",
      "{'type': 29, 'word': ['text', 'prompt'], 'time': '2/8', 'size': 67.17970000000003}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '2/11', 'size': 1642.1700000000012}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/11', 'size': 525.8294000000001}\n",
      "{'type': 30, 'word': ['crypto', 'nft'], 'time': '2/11', 'size': 169.25180000000003}\n",
      "{'type': 31, 'word': ['memecoin', 'elonmusk', 'opera', 'chatgpt3', 'https'], 'time': '2/11', 'size': 219.78429999999997}\n",
      "{'type': 32, 'word': ['seo', 'marketing', 'content'], 'time': '2/11', 'size': 115.82019999999999}\n",
      "{'type': 33, 'word': ['app', 'browser'], 'time': '2/11', 'size': 66.72830000000002}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'openai', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'bard'], 'time': '2/14', 'size': 2960.7266999999965}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/14', 'size': 641.1872}\n",
      "{'type': 34, 'word': ['valentine', 'valentines'], 'time': '2/14', 'size': 133.78710000000004}\n",
      "{'type': 31, 'word': ['chatgpt3', 'elonmusk', 'opera', 'memecoin', 'https'], 'time': '2/14', 'size': 132.28830000000005}\n",
      "{'type': 32, 'word': ['seo', 'business', 'marketing', 'content'], 'time': '2/14', 'size': 156.36530000000002}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'openai', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'bard'], 'time': '2/17', 'size': 1446.476900000001}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/17', 'size': 308.6911999999999}\n",
      "{'type': 31, 'word': ['chatgpt3', 'elonmusk', 'opera', 'elon', 'musk', 'memecoin', 'https'], 'time': '2/17', 'size': 195.90120000000007}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '2/20', 'size': 2500.8662000000045}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/20', 'size': 629.5687999999998}\n",
      "{'type': 35, 'word': ['crypto', 'trading', 'web3'], 'time': '2/20', 'size': 259.20050000000003}\n",
      "{'type': 36, 'word': ['marketing', 'business'], 'time': '2/20', 'size': 74.05640000000001}\n",
      "{'type': 37, 'word': ['prompts', 'text', 'prompt'], 'time': '2/20', 'size': 85.08500000000004}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'china', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '2/23', 'size': 1468.4784000000018}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/23', 'size': 570.5193999999999}\n",
      "{'type': 38, 'word': ['crypto', 'altcoin', 'cryptocurrency', 'web3'], 'time': '2/23', 'size': 289.7228}\n",
      "{'type': 39, 'word': ['malware', 'phishing'], 'time': '2/23', 'size': 66.3043}\n",
      "{'type': 36, 'word': ['business', 'marketing'], 'time': '2/23', 'size': 60.262100000000004}\n",
      "{'type': 37, 'word': ['text', 'prompt', 'prompts'], 'time': '2/23', 'size': 78.27890000000001}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'bard', 'azure', 'chatgpt3', 'msft', 'gpt4'], 'time': '2/26', 'size': 2030.3831999999984}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/26', 'size': 561.6650999999999}\n",
      "{'type': 40, 'word': ['musk', 'elon'], 'time': '2/26', 'size': 111.95159999999998}\n",
      "{'type': 41, 'word': ['elonmusk', 'altcoin', 'altcoins', 'https'], 'time': '2/26', 'size': 174.95340000000004}\n",
      "{'type': 42, 'word': ['crypto', 'metaverse', 'cryptocurrency', 'web3', 'bitcoin'], 'time': '2/26', 'size': 172.21259999999998}\n",
      "{'type': 43, 'word': ['twitter', 'linkedin', 'podcast'], 'time': '2/26', 'size': 85.0437}\n",
      "{'type': 44, 'word': ['prompts', 'code', 'prompt'], 'time': '2/26', 'size': 79.74880000000002}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4'], 'time': '3/1', 'size': 2630.0507999999995}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/1', 'size': 725.0462999999997}\n",
      "{'type': 45, 'word': ['artificialintelligence', 'elonmusk', 'vr'], 'time': '3/1', 'size': 371.4291}\n",
      "{'type': 46, 'word': ['trading', 'metaverse', 'crypto', 'tech'], 'time': '3/1', 'size': 296.78310000000005}\n",
      "{'type': 47, 'word': ['prompts', 'resume'], 'time': '3/1', 'size': 132.11219999999997}\n",
      "{'type': 48, 'word': ['seo', 'marketing', 'copywriting'], 'time': '3/1', 'size': 140.0906}\n",
      "{'type': 41, 'word': ['elonmusk', 'elon', 'altcoins', 'musk', 'altcoin', 'https'], 'time': '3/1', 'size': 82.23430000000002}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4'], 'time': '3/4', 'size': 1654.7122000000008}\n",
      "{'type': 49, 'word': ['chatbot', 'bot', 'robot', 'intelligence', 'app'], 'time': '3/4', 'size': 376.99890000000005}\n",
      "{'type': 45, 'word': ['artificialintelligence', 'elonmusk', 'elon', 'vr', 'musk'], 'time': '3/4', 'size': 289.85869999999994}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/4', 'size': 227.2812}\n",
      "{'type': 50, 'word': ['upsc', 'exam'], 'time': '3/4', 'size': 104.91070000000005}\n",
      "{'type': 51, 'word': ['resume', 'prompts', 'tweet'], 'time': '3/4', 'size': 127.72639999999996}\n",
      "{'type': 52, 'word': ['metaverse', 'crypto', 'nft'], 'time': '3/4', 'size': 137.66120000000006}\n",
      "{'type': 53, 'word': ['chatgpt3', 'nlp'], 'time': '3/4', 'size': 50.15369999999999}\n",
      "{'type': 54, 'word': ['marketing', 'business'], 'time': '3/4', 'size': 47.95389999999999}\n",
      "{'type': 41, 'word': ['elonmusk', 'elon', 'altcoins', 'musk', 'altcoin', 'https'], 'time': '3/4', 'size': 44.3973}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4'], 'time': '3/7', 'size': 1980.0892000000013}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/7', 'size': 700.6083}\n",
      "{'type': 55, 'word': ['artificialintelligence', 'chomsky', 'westworld', 'chatgpt3', 'southpark'], 'time': '3/7', 'size': 339.86550000000005}\n",
      "{'type': 56, 'word': ['prompts', 'prompt'], 'time': '3/7', 'size': 82.9571}\n",
      "{'type': 57, 'word': ['blog', 'podcast'], 'time': '3/7', 'size': 50.49119999999999}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4'], 'time': '3/10', 'size': 1660.0196}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/10', 'size': 279.1637}\n",
      "{'type': 55, 'word': ['westworld', 'artificialintelligence', 'chatgpt3', 'chatgpt4', 'southpark', 'chomsky'], 'time': '3/10', 'size': 351.8026999999999}\n",
      "{'type': 58, 'word': ['episode', 'podcast'], 'time': '3/10', 'size': 49.624300000000005}\n",
      "{'type': 59, 'word': ['prompts', 'prompt', 'text'], 'time': '3/10', 'size': 66.90670000000001}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4'], 'time': '3/13', 'size': 4480.077999999995}\n",
      "{'type': 60, 'word': ['chatgpt4', 'chatgpt3', 'elonmusk', 'nlp'], 'time': '3/13', 'size': 585.7348999999997}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/13', 'size': 720.0681}\n",
      "{'type': 59, 'word': ['text', 'prompt', 'prompts'], 'time': '3/13', 'size': 137.4864}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'copilot', 'gpt4'], 'time': '3/16', 'size': 4035.682900000003}\n",
      "{'type': 61, 'word': ['chatgpt4', 'artificialintelligence', 'elonmusk', 'baidu', 'bitcoin', 'chatgpt3', 'doubled', 'btc'], 'time': '3/16', 'size': 977.8660999999993}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/16', 'size': 623.9029000000002}\n",
      "{'type': 62, 'word': ['crypto', 'nft'], 'time': '3/16', 'size': 154.33679999999995}\n",
      "{'type': 59, 'word': ['text', 'prompt', 'prompts'], 'time': '3/16', 'size': 99.00019999999998}\n",
      "{'type': 63, 'word': ['marketing', 'copywriter', 'business'], 'time': '3/16', 'size': 122.50589999999997}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'copilot', 'gpt4'], 'time': '3/19', 'size': 2798.754100000002}\n",
      "{'type': 61, 'word': ['baidu', 'artificialintelligence', 'chatgpt3', 'elonmusk', 'btc', 'chatgpt4', 'bitcoin', 'doubled'], 'time': '3/19', 'size': 389.82879999999983}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/19', 'size': 493.6056999999999}\n",
      "{'type': 64, 'word': ['crypto', 'bitcoin', 'nfts', 'binance', 'nft', 'stocks'], 'time': '3/19', 'size': 238.89089999999996}\n",
      "{'type': 65, 'word': ['prompts', 'prompt', 'tweet', 'code', 'text', 'tweets'], 'time': '3/19', 'size': 237.17739999999995}\n",
      "{'type': 63, 'word': ['copywriter', 'business', 'marketing'], 'time': '3/19', 'size': 58.280499999999996}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'github', 'copilot', 'gpt4'], 'time': '3/22', 'size': 3699.665200000001}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/22', 'size': 733.5094000000004}\n",
      "{'type': 61, 'word': ['baidu', 'artificialintelligence', 'chatgpt3', 'elonmusk', 'btc', 'chatgpt4', 'bitcoin', 'agi', 'doubled'], 'time': '3/22', 'size': 361.4167}\n",
      "{'type': 66, 'word': ['plugins', 'copilot', 'app', 'plugin'], 'time': '3/22', 'size': 279.36609999999996}\n",
      "{'type': 65, 'word': ['text', 'tweet', 'code', 'tweets', 'prompts', 'prompt'], 'time': '3/22', 'size': 207.9008}\n",
      "{'type': 67, 'word': ['seo', 'marketing', 'copywriting'], 'time': '3/22', 'size': 134.72000000000003}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'github', 'copilot', 'gpt4'], 'time': '3/25', 'size': 2655.4832}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/25', 'size': 233.7944}\n",
      "{'type': 68, 'word': ['chatgpt4', 'ticker', 'candle', 'agi', 'elonmusk', 'chatgpt3'], 'time': '3/25', 'size': 432.53350000000006}\n",
      "{'type': 69, 'word': ['binance', 'crypto', 'bitcoin'], 'time': '3/25', 'size': 232.4995999999999}\n",
      "{'type': 65, 'word': ['text', 'tweet', 'code', 'tweets', 'prompts', 'prompt'], 'time': '3/25', 'size': 164.1951}\n",
      "{'type': 66, 'word': ['app', 'copilot', 'plugins', 'plugin'], 'time': '3/25', 'size': 103.95190000000002}\n",
      "{'type': 70, 'word': ['writing', 'programming'], 'time': '3/25', 'size': 80.65520000000001}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'agi', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'github', 'copilot', 'gpt4'], 'time': '3/28', 'size': 2707.130699999999}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/28', 'size': 453.065}\n",
      "{'type': 68, 'word': ['ticker', 'candle', 'chatgpt3', 'elonmusk', 'doge', 'chatgpt4', 'elon', 'musk', 'agi'], 'time': '3/28', 'size': 251.92799999999994}\n",
      "{'type': 65, 'word': ['text', 'tweet', 'code', 'tweets', 'prompts', 'prompt'], 'time': '3/28', 'size': 111.7335}\n",
      "{'type': 66, 'word': ['app', 'copilot', 'plugins', 'plugin'], 'time': '3/28', 'size': 58.892800000000015}\n"
     ]
    }
   ],
   "source": [
    "#pictureGephi(file_list,seed)   #获得可用于gephi画图的_node_type csv\n",
    "list_exist_all_topics = getTopicChange(file_list)       #获得话题,跑了一次存了就行,但是后面的代码需要这个值。  好在不花时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeTwoDic(dic_a,dic_b):\n",
    "    #用来合并字典，字典中有word和weight\n",
    "    #相同元素则更新值，否则加入\n",
    "    #原始形式为{word:[q,q,w,w],weight:[1,1,2,2]}\n",
    "    #print(dic_a)\n",
    "    #先把a的词更新weight\n",
    "    for word_a in dic_a['word']:\n",
    "        for word_b in dic_b['word']:\n",
    "            if word_a==word_b:\n",
    "                dic_a['weight'][dic_a['word'].index(word_a)] = dic_a['weight'][dic_a['word'].index(word_a)]+ dic_b['weight'][dic_b['word'].index(word_b)]   \n",
    "    #b中新词加入a\n",
    "    for word_b in dic_b['word']:\n",
    "        if(word_b not in dic_a['word']):\n",
    "            dic_a['word'].append(word_b)\n",
    "            dic_a['weight'].append(dic_b['weight'][dic_b['word'].index(word_b)])\n",
    "    print(len(dic_a['word']))        \n",
    "    return dic_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '2/20', 'day': '2023-02-20'}\n",
      "总数量5948\n",
      "取词中: 1.09983184799058347653 \n",
      "总数量6079\n",
      "取词中: 1.0 983547219480186464\n",
      "8838\n",
      "{'time': '2/23', 'day': '2023-02-23'}\n",
      "总数量6018\n",
      "取词中: 1.09983380422137285454 \n",
      "总数量5135\n",
      "取词中: 1.09980522010128563644 \n",
      "8331\n",
      "{'time': '2/26', 'day': '2023-02-26'}\n",
      "总数量3373\n",
      "取词中: 1.0997034400948992445 \n",
      "总数量5212\n",
      "取词中: 1.09980809825369415454 \n",
      "6833\n",
      "{'time': '3/1', 'day': '2023-03-01'}\n",
      "总数量5751\n",
      "取词中: 1.09982608695652185656 \n",
      "总数量6402\n",
      "取词中: 1.0 984377441024847666\n",
      "8598\n",
      "{'time': '3/4', 'day': '2023-03-04'}\n",
      "总数量4144\n",
      "取词中: 1.0 97586290127927345\n",
      "总数量4149\n",
      "取词中: 1.09975891996142727656 \n",
      "7034\n",
      "{'time': '3/7', 'day': '2023-03-06'}\n",
      "总数量5265\n",
      "取词中: 1.09981003039513685557 \n",
      "总数量5132\n",
      "取词中: 1.09980510621711176556 \n",
      "8098\n"
     ]
    }
   ],
   "source": [
    "day_verify=[\n",
    "    #前后两个参数并不是一个日期。第二个参数是日期，第一个参数是所属的组\n",
    "    #{'time':'2/14','day':'2023-02-15'},\n",
    "    #{'time':'2/14','day':'2023-02-16'},\n",
    "    #{'time':'2/17','day':'2023-02-17'},\n",
    "    #{'time':'2/17','day':'2023-02-18'},\n",
    "    {'time':'2/20','day':'2023-02-20'},\n",
    "    {'time':'2/20','day':'2023-02-21'},\n",
    "    {'time':'2/23','day':'2023-02-23'},\n",
    "    {'time':'2/23','day':'2023-02-24'},\n",
    "    {'time':'2/26','day':'2023-02-26'},\n",
    "    {'time':'2/26','day':'2023-02-27'},\n",
    "    {'time':'3/1','day':'2023-03-01'},\n",
    "    {'time':'3/1','day':'2023-03-02'},\n",
    "    {'time':'3/4','day':'2023-03-04'},\n",
    "    {'time':'3/4','day':'2023-03-05'},\n",
    "    {'time':'3/7','day':'2023-03-06'},\n",
    "    {'time':'3/7','day':'2023-03-07'},\n",
    "]\n",
    "data_number=0   #表示取全部数据\n",
    "list_temporary=[]\n",
    "for i in range(0,len(day_verify),2):\n",
    "    print(day_verify[i])\n",
    "    pos_index=time_list.index(day_verify[i]['time'])\n",
    "    topics=list_exist_all_topics[pos_index-1]  #要找上一次的\n",
    "    data_number=0 \n",
    "    dic_1,doclist_1 = GetKeyBertWord('GPT',day_verify[i]['day'])\n",
    "    data_number=0 \n",
    "    dic_2,doclist_2 = GetKeyBertWord('GPT',day_verify[i+1]['day'])\n",
    "    dic=mergeTwoDic(dic_1,dic_2)\n",
    "    doclist=doclist_1+doclist_2\n",
    "    sorted_word = sorted(dic['word'], key=lambda x: dic['weight'][dic['word'].index(x)],reverse=True)  #根据weight操作word排序\n",
    "    sorted_weight=sorted(dic['weight'],reverse=True)\n",
    "    dic={}\n",
    "    dic['sorted_word']=sorted_word[:50]\n",
    "    dic['sorted_weight']=sorted_weight[:50]\n",
    "    dic['topics']=topics\n",
    "    list_temporary.append(dic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'old_topic': [{'type': 0, 'change': '上升', 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'openai', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'bard'], 'pre_size': 2813.579484000001, 'time': '2/17', 'influence_word': ['generativeai', 'openaichatgpt', 'machinelearning', 'controversial', 'advertising', 'aipad']}, {'type': 1, 'change': '上升', 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'pre_size': 688.056222, 'time': '2/17', 'influence_word': ['artificialintelligence', 'generativeai', 'openaichatgpt', 'twitter', 'machinelearning', 'controversial', 'advertising', 'aipad']}, {'type': 31, 'change': '相对稳定', 'word': ['chatgpt3', 'elonmusk', 'opera', 'elon', 'musk', 'memecoin', 'https'], 'pre_size': 193.43465399999997, 'time': '2/17', 'influence_word': ['openaichatgpt', 'controversial']}], 'new_topic': [['trading', 'crypto', 'crypto', 'web3'], ['marketing', 'advertising'], ['prompts', 'prompt']]}\n",
      "{'old_topic': [{'type': 0, 'change': '相对稳定', 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai', 'china'], 'pre_size': 2646.2282439999985, 'time': '2/20', 'influence_word': ['generativeai', 'openaichatgpt', 'altcoin', 'altcoins', 'machinelearning', 'bingchat']}, {'type': 1, 'change': '相对稳定', 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'pre_size': 731.734142, 'time': '2/20', 'influence_word': ['artificialintelligence', 'generativeai', 'openaichatgpt', 'twitter', 'machinelearning', 'bingchat', 'nvidia']}, {'type': 35, 'change': '下降', 'word': ['crypto', 'trading', 'web3'], 'pre_size': 146.19819199999995, 'time': '2/20', 'influence_word': ['coin', 'invest', 'stocks', 'altcoin', 'altcoins', 'twitter', 'cryptocurrency', 'cybersecurity']}, {'type': 36, 'change': '相对稳定', 'word': ['marketing', 'business'], 'pre_size': 82.40157, 'time': '2/20', 'influence_word': ['generativeai', 'seo', 'webinar', 'nvidia']}, {'type': 37, 'change': '下降', 'word': ['prompts', 'text', 'prompt'], 'pre_size': 64.861844, 'time': '2/20', 'influence_word': []}], 'new_topic': [['malware', 'phishing'], ['altcoin', 'cryptocurrency']]}\n",
      "{'old_topic': [{'type': 0, 'change': '上升', 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'china', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai', 'snapchat'], 'pre_size': 1983.8777859999993, 'time': '2/23', 'influence_word': ['generativeai', 'altcoins', 'openaichatgpt', 'linkedin', 'bullish', 'aipad']}, {'type': 1, 'change': '相对稳定', 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'pre_size': 528.2526699999999, 'time': '2/23', 'influence_word': ['artificialintelligence', 'generativeai', 'openaichatgpt', 'twitter', 'linkedin', 'bullish', 'aipad', 'workers']}, {'type': 38, 'change': '相对稳定', 'word': ['crypto', 'altcoin', 'cryptocurrency', 'web3', 'metaverse'], 'pre_size': 233.169742, 'time': '2/23', 'influence_word': ['altcoins']}, {'type': 39, 'change': '下降', 'word': ['malware', 'phishing'], 'pre_size': 0.0, 'time': '2/23', 'influence_word': []}, {'type': 36, 'change': '下降', 'word': ['business', 'marketing'], 'pre_size': 26.162429999999993, 'time': '2/23', 'influence_word': ['generativeai', 'seo', 'linkedin', 'workers']}, {'type': 37, 'change': '相对稳定', 'word': ['text', 'prompt', 'prompts'], 'pre_size': 64.573834, 'time': '2/23', 'influence_word': []}], 'new_topic': [['altcoins', 'https', 'elonmusk', 'https'], ['seo', 'ads'], ['twitter', 'linkedin', 'linkedin', 'podcast'], ['jobs', 'workers']]}\n",
      "{'old_topic': [{'type': 0, 'change': '上升', 'word': ['bot', 'ai', 'app', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'bard', 'azure', 'chatgpt3', 'msft', 'gpt4', 'whisper', 'apis'], 'pre_size': 3123.731394000002, 'time': '2/26', 'influence_word': ['generativeai', 'bullish', 'chatgptapi', 'bingchat', 'copywriting', 'openaichatgpt']}, {'type': 1, 'change': '上升', 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'pre_size': 790.5321720000003, 'time': '2/26', 'influence_word': ['artificialintelligence', 'aichatbot', 'generativeai', 'chatbotai', 'bullish', 'chatgptapi', 'bingchat', 'copywriting', 'openaichatgpt']}, {'type': 40, 'change': '相对稳定', 'word': ['musk', 'elon'], 'pre_size': 109.87440399999998, 'time': '2/26', 'influence_word': []}, {'type': 41, 'change': '下降', 'word': ['elonmusk', 'altcoin', 'altcoins', 'https', 'vr'], 'pre_size': 88.001414, 'time': '2/26', 'influence_word': ['trading']}, {'type': 42, 'change': '下降', 'word': ['crypto', 'metaverse', 'cryptocurrency', 'web3', 'bitcoin'], 'pre_size': 134.747346, 'time': '2/26', 'influence_word': []}, {'type': 43, 'change': '相对稳定', 'word': ['twitter', 'linkedin', 'podcast'], 'pre_size': 76.018372, 'time': '2/26', 'influence_word': ['generativeai', 'seo', 'marketing', 'cybersecurity']}, {'type': 44, 'change': '上升', 'word': ['prompts', 'code', 'prompt', 'resume'], 'pre_size': 122.52194399999996, 'time': '2/26', 'influence_word': ['artificialintelligence', 'aichatbot', 'seo', 'chatbotai', 'cybersecurity', 'writing', 'bingchat', 'copywriting', 'puts']}], 'new_topic': [['seo', 'copywriting', 'marketing', 'copywriting']]}\n",
      "{'old_topic': [{'type': 0, 'change': '下降', 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4', 'nlp'], 'pre_size': 1811.3207860000002, 'time': '3/1', 'influence_word': ['upsc', 'generativeai', 'iot', 'openaichatgpt', 'robotics', 'nftcommunity', 'machinelearning', 'aiethics', 'bingchat', 'quantum', 'cloud', 'youtube']}, {'type': 1, 'change': '下降', 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'pre_size': 555.0284700000001, 'time': '3/1', 'influence_word': ['aichatbot', 'generativeai', 'chatbotai', 'iot', 'openaichatgpt', 'robotics', 'machinelearning', 'aiethics', 'bingchat', 'longest', 'quantum', 'cloud']}, {'type': 45, 'change': '下降', 'word': ['artificialintelligence', 'elonmusk', 'vr'], 'pre_size': 277.38666399999994, 'time': '3/1', 'influence_word': ['upsc', 'aichatbot', 'generativeai', 'chatbotai', 'iot', 'exam', 'writing', 'openaichatgpt', 'art', 'robotics', 'machinelearning', 'cybersecurity', 'aiethics', 'bingchat', 'data', 'quantum', 'tweet', 'youtube']}, {'type': 46, 'change': '下降', 'word': ['trading', 'metaverse', 'crypto', 'tech'], 'pre_size': 106.99413799999998, 'time': '3/1', 'influence_word': ['chatbotai', 'iot', 'art', 'robotics', 'machinelearning', 'cybersecurity', 'aiethics', 'quantum', 'cloud', 'youtube']}, {'type': 47, 'change': '相对稳定', 'word': ['prompts', 'resume'], 'pre_size': 128.02567399999998, 'time': '3/1', 'influence_word': ['aichatbot', 'chatbotai', 'exam', 'writing', 'art', 'bingchat', 'data', 'tweet']}, {'type': 48, 'change': '下降', 'word': ['seo', 'marketing', 'copywriting'], 'pre_size': 40.053808000000004, 'time': '3/1', 'influence_word': ['nftcommunity']}, {'type': 41, 'change': '相对稳定', 'word': ['elonmusk', 'elon', 'altcoins', 'musk', 'altcoin', 'https'], 'pre_size': 87.10883199999999, 'time': '3/1', 'influence_word': []}], 'new_topic': [['upsc', 'exam'], ['robotics', 'quantum']]}\n",
      "{'old_topic': [{'type': 0, 'change': '上升', 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4', 'slack', 'ceo'], 'pre_size': 2462.327634, 'time': '3/4', 'influence_word': ['generativeai', 'openaichatgpt', 'airdrop', 'nftcommunity']}, {'type': 49, 'change': '相对稳定', 'word': ['chatbot', 'bot', 'robot', 'intelligence', 'app'], 'pre_size': 392.07440399999996, 'time': '3/4', 'influence_word': ['generativeai', 'aichatbot', 'openaichatgpt', 'chatbotai', 'machinelearning']}, {'type': 45, 'change': '上升', 'word': ['artificialintelligence', 'elonmusk', 'elon', 'vr', 'musk', 'ceo'], 'pre_size': 364.54214200000007, 'time': '3/4', 'influence_word': ['aichatbot', 'openaichatgpt', 'airdrop', 'chatbotai', 'machinelearning', 'titles']}, {'type': 1, 'change': '上升', 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'pre_size': 620.508996, 'time': '3/4', 'influence_word': ['generativeai', 'aichatbot', 'openaichatgpt', 'chatbotai', 'machinelearning', 'titles', 'longest']}, {'type': 50, 'change': '下降', 'word': ['upsc', 'exam'], 'pre_size': 0.0, 'time': '3/4', 'influence_word': []}, {'type': 51, 'change': '相对稳定', 'word': ['resume', 'prompts', 'tweet'], 'pre_size': 125.957812, 'time': '3/4', 'influence_word': ['aichatbot', 'writing', 'seo', 'chatbotai', 'jobs', 'blog']}, {'type': 52, 'change': '相对稳定', 'word': ['metaverse', 'crypto', 'nft'], 'pre_size': 155.25349200000002, 'time': '3/4', 'influence_word': ['nftcommunity', 'bitcoin']}, {'type': 53, 'change': '相对稳定', 'word': ['chatgpt3', 'nlp'], 'pre_size': 41.219626, 'time': '3/4', 'influence_word': ['generativeai', 'aichatbot', 'writing', 'openaichatgpt', 'chatbotai', 'blog', 'machinelearning', 'art']}, {'type': 54, 'change': '相对稳定', 'word': ['marketing', 'business'], 'pre_size': 52.54663600000001, 'time': '3/4', 'influence_word': ['generativeai', 'seo', 'blog', 'nftcommunity']}, {'type': 41, 'change': '上升', 'word': ['elonmusk', 'elon', 'altcoins', 'musk', 'altcoin', 'https', 'ceo'], 'pre_size': 53.335302, 'time': '3/4', 'influence_word': []}], 'new_topic': [['blog', 'podcast'], ['students', 'teachers']]}\n"
     ]
    }
   ],
   "source": [
    "for data in list_temporary:\n",
    "    result_get = predictTopic(data['sorted_word'],data['sorted_weight'],data['topics'])\n",
    "    print(result_get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 0, 'word': ['ai', 'openai', 'google', 'bing', 'microsoft', 'bot', 'gpt3', 'search'], 'time': '1/6', 'size': 1603.256100000001}\n",
      "{'type': 1, 'word': ['chatbot', 'chatbots', 'language', 'generative', 'intelligence', 'technology'], 'time': '1/6', 'size': 362.46159999999986}\n",
      "{'type': 2, 'word': ['chatgpt3', 'prompts', 'tweet', 'text', 'tweets', 'code', 'nlp'], 'time': '1/6', 'size': 200.7716}\n",
      "{'type': 3, 'word': ['seo', 'content'], 'time': '1/6', 'size': 57.10700000000001}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/6', 'size': 82.14900000000002}\n",
      "{'type': 0, 'word': ['ai', 'openai', 'microsoft', 'google', 'bing', 'bot', 'gpt3', 'app', 'robot', 'app', 'robot'], 'time': '1/9', 'size': 1883.8482}\n",
      "{'type': 1, 'word': ['chatbot', 'chatbots', 'generative', 'language', 'technology', 'intelligence'], 'time': '1/9', 'size': 316.4374999999999}\n",
      "{'type': 5, 'word': ['chatgpt3', 'msft', 'nlp', 'text', 'prompts', 'https', 'elonmusk', 'code'], 'time': '1/9', 'size': 211.5415}\n",
      "{'type': 6, 'word': ['writing', 'essays', 'essay'], 'time': '1/9', 'size': 78.1586}\n",
      "{'type': 7, 'word': ['marketing', 'business'], 'time': '1/9', 'size': 48.08240000000001}\n",
      "{'type': 4, 'word': ['students', 'teachers'], 'time': '1/9', 'size': 43.4782}\n",
      "{'type': 0, 'word': ['gpt3', 'bot', 'ai', 'app', 'robot', 'search', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/12', 'size': 1570.5742000000014}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/12', 'size': 306.8595999999999}\n",
      "{'type': 8, 'word': ['writing', 'essays', 'essay', 'education', 'teaching'], 'time': '1/12', 'size': 127.84559999999999}\n",
      "{'type': 5, 'word': ['nlp', 'text', 'chatgpt3', 'code', 'elonmusk', 'msft', 'chatgpt4', 'prompts', 'https'], 'time': '1/12', 'size': 118.41250000000001}\n",
      "{'type': 9, 'word': ['prompts', 'text', 'tweet', 'tweets', 'code'], 'time': '1/12', 'size': 116.15810000000002}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/12', 'size': 54.170300000000005}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'robot', 'search', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/15', 'size': 1650.7189999999996}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/15', 'size': 366.32140000000004}\n",
      "{'type': 8, 'word': ['education', 'teaching', 'essays', 'writing', 'essay'], 'time': '1/15', 'size': 66.39440000000002}\n",
      "{'type': 5, 'word': ['nlp', 'text', 'chatgpt3', 'code', 'elonmusk', 'msft', 'chatgpt4', 'prompts', 'https'], 'time': '1/15', 'size': 101.60480000000001}\n",
      "{'type': 10, 'word': ['seo', 'marketing', 'business', 'content'], 'time': '1/15', 'size': 102.3063}\n",
      "{'type': 11, 'word': ['song', 'tweet', 'poem'], 'time': '1/15', 'size': 67.5178}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/15', 'size': 53.741799999999984}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'robot', 'search', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/18', 'size': 1702.4551}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/18', 'size': 349.8528}\n",
      "{'type': 10, 'word': ['seo', 'business', 'marketing', 'content'], 'time': '1/18', 'size': 86.0529}\n",
      "{'type': 5, 'word': ['nlp', 'text', 'chatgpt3', 'code', 'elonmusk', 'msft', 'chatgpt4', 'prompts', 'https'], 'time': '1/18', 'size': 97.13019999999999}\n",
      "{'type': 12, 'word': ['prompts', 'text', 'prompt'], 'time': '1/18', 'size': 76.55169999999998}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/18', 'size': 49.63000000000001}\n",
      "{'type': 11, 'word': ['song', 'tweet', 'poem'], 'time': '1/18', 'size': 44.2444}\n",
      "{'type': 13, 'word': ['crypto', 'binance', 'stocks', 'bitcoin', 'layoffs'], 'time': '1/18', 'size': 112.3345}\n",
      "{'type': 14, 'word': ['podcast', 'blog'], 'time': '1/18', 'size': 38.2339}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'api', 'robot', 'search', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/21', 'size': 1472.487999999998}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/21', 'size': 346.8933}\n",
      "{'type': 15, 'word': ['microsoft', 'google', 'chatgpt3', 'mba', 'exam', 'msft', 'nlp', 'https'], 'time': '1/21', 'size': 465.0453000000001}\n",
      "{'type': 13, 'word': ['stocks', 'binance', 'layoffs', 'crypto', 'bitcoin'], 'time': '1/21', 'size': 154.92600000000002}\n",
      "{'type': 4, 'word': ['teachers', 'students', 'schools'], 'time': '1/21', 'size': 46.1112}\n",
      "{'type': 16, 'word': ['prompts', 'text', 'tweet', 'prompt', 'tweets'], 'time': '1/21', 'size': 106.96289999999998}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'gpt4', 'robot', 'search', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '1/24', 'size': 1732.8550999999998}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/24', 'size': 349.2432000000001}\n",
      "{'type': 15, 'word': ['nlp', 'chatgpt3', 'mba', 'msft', 'exams', 'buzzfeed', 'google', 'https', 'microsoft', 'exam'], 'time': '1/24', 'size': 208.27710000000002}\n",
      "{'type': 17, 'word': ['seo', 'marketing', 'content', 'business'], 'time': '1/24', 'size': 107.9999}\n",
      "{'type': 16, 'word': ['text', 'tweet', 'tweets', 'prompts', 'prompt'], 'time': '1/24', 'size': 104.6243}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'api', 'robot', 'search', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '1/27', 'size': 1411.4276999999986}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/27', 'size': 288.42130000000003}\n",
      "{'type': 15, 'word': ['nlp', 'chatgpt3', 'elonmusk', 'mba', 'msft', 'exams', 'buzzfeed', 'google', 'https', 'microsoft', 'exam'], 'time': '1/27', 'size': 135.305}\n",
      "{'type': 18, 'word': ['text', 'nlp', 'prompt', 'prompts', 'code'], 'time': '1/27', 'size': 112.5309}\n",
      "{'type': 19, 'word': ['students', 'teachers'], 'time': '1/27', 'size': 43.9959}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'app', 'gpt4', 'robot', 'search', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '1/30', 'size': 1800.3766}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'generative', 'chatbots', 'language'], 'time': '1/30', 'size': 368.9661999999999}\n",
      "{'type': 20, 'word': ['artificialintelligence', 'baidu', 'chatgpt3', 'elonmusk', 'https', 'nlp'], 'time': '1/30', 'size': 312.9301999999998}\n",
      "{'type': 18, 'word': ['nlp', 'text', 'code', 'prompts', 'prompt'], 'time': '1/30', 'size': 86.79860000000002}\n",
      "{'type': 21, 'word': ['seo', 'writing', 'marketing', 'automation', 'content', 'programming'], 'time': '1/30', 'size': 147.6582}\n",
      "{'type': 22, 'word': ['twitter', 'gmail'], 'time': '1/30', 'size': 45.9057}\n",
      "{'type': 19, 'word': ['teachers', 'students'], 'time': '1/30', 'size': 45.77380000000001}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'openai'], 'time': '2/2', 'size': 1824.8246000000001}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'language'], 'time': '2/2', 'size': 374.4281999999999}\n",
      "{'type': 23, 'word': ['bias', 'biased', 'woke', 'biden'], 'time': '2/2', 'size': 102.9074}\n",
      "{'type': 24, 'word': ['twitter', 'text', 'prompts', 'youtube', 'tiktok', 'code', 'tweets'], 'time': '2/2', 'size': 147.09240000000003}\n",
      "{'type': 25, 'word': ['marketing', 'business'], 'time': '2/2', 'size': 38.19749999999999}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'openai', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'bard'], 'time': '2/5', 'size': 5023.005699999998}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/5', 'size': 805.5671999999996}\n",
      "{'type': 26, 'word': ['artificialintelligence', 'elonmusk', 'chatgpt3', 'baidu', 'https'], 'time': '2/5', 'size': 516.9139000000006}\n",
      "{'type': 27, 'word': ['bias', 'woke', 'racist'], 'time': '2/5', 'size': 106.2553}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '2/8', 'size': 5410.132099999998}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/8', 'size': 882.8296999999995}\n",
      "{'type': 26, 'word': ['baidu', 'artificialintelligence', 'chatgpt3', 'elonmusk', 'https'], 'time': '2/8', 'size': 529.2777999999997}\n",
      "{'type': 28, 'word': ['search', 'browser'], 'time': '2/8', 'size': 103.64699999999999}\n",
      "{'type': 29, 'word': ['text', 'prompt'], 'time': '2/8', 'size': 67.17970000000003}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai'], 'time': '2/11', 'size': 1642.1700000000012}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/11', 'size': 525.8294000000001}\n",
      "{'type': 30, 'word': ['crypto', 'nft'], 'time': '2/11', 'size': 169.25180000000003}\n",
      "{'type': 31, 'word': ['memecoin', 'elonmusk', 'opera', 'chatgpt3', 'https'], 'time': '2/11', 'size': 219.78429999999997}\n",
      "{'type': 32, 'word': ['seo', 'marketing', 'content'], 'time': '2/11', 'size': 115.82019999999999}\n",
      "{'type': 33, 'word': ['app', 'browser'], 'time': '2/11', 'size': 66.72830000000002}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'openai', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'bard'], 'time': '2/14', 'size': 2960.7266999999965}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/14', 'size': 641.1872}\n",
      "{'type': 34, 'word': ['valentine', 'valentines'], 'time': '2/14', 'size': 133.78710000000004}\n",
      "{'type': 31, 'word': ['chatgpt3', 'elonmusk', 'opera', 'memecoin', 'https'], 'time': '2/14', 'size': 132.28830000000005}\n",
      "{'type': 32, 'word': ['seo', 'business', 'marketing', 'content'], 'time': '2/14', 'size': 156.36530000000002}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'api', 'openai', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'gpt4', 'microsoft', 'bard'], 'time': '2/17', 'size': 1446.476900000001, 'pmi_baseline': 6.2661027297152225}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/17', 'size': 308.6911999999999, 'pmi_baseline': 6.314997742357969}\n",
      "{'type': 31, 'word': ['chatgpt3', 'elonmusk', 'opera', 'elon', 'musk', 'memecoin', 'https'], 'time': '2/17', 'size': 195.90120000000007, 'pmi_baseline': 6.593230735369277}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai', 'china'], 'time': '2/20', 'size': 2500.8662000000045, 'pmi_baseline': 6.2661027297152225}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/20', 'size': 629.5687999999998, 'pmi_baseline': 6.314997742357969}\n",
      "{'type': 35, 'word': ['crypto', 'trading', 'web3'], 'time': '2/20', 'size': 259.20050000000003, 'pmi_baseline': 6.762324153628665}\n",
      "{'type': 36, 'word': ['marketing', 'business'], 'time': '2/20', 'size': 74.05640000000001, 'pmi_baseline': 5.80315157395992}\n",
      "{'type': 37, 'word': ['prompts', 'text', 'prompt'], 'time': '2/20', 'size': 85.08500000000004, 'pmi_baseline': 7.27903205257864}\n",
      "{'type': 0, 'word': ['gpt3', 'azure', 'bot', 'ai', 'chatgpt3', 'app', 'bard', 'china', 'gpt4', 'robot', 'search', 'msft', 'siri', 'bing', 'google', 'api', 'microsoft', 'openai', 'snapchat'], 'time': '2/23', 'size': 1468.4784000000018, 'pmi_baseline': 6.251898067744533}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/23', 'size': 570.5193999999999, 'pmi_baseline': 6.314997742357969}\n",
      "{'type': 38, 'word': ['crypto', 'altcoin', 'cryptocurrency', 'web3', 'metaverse'], 'time': '2/23', 'size': 289.7228, 'pmi_baseline': 8.531205622552715}\n",
      "{'type': 39, 'word': ['malware', 'phishing'], 'time': '2/23', 'size': 66.3043, 'pmi_baseline': 9.617306748747339}\n",
      "{'type': 36, 'word': ['business', 'marketing'], 'time': '2/23', 'size': 60.262100000000004, 'pmi_baseline': 5.80315157395992}\n",
      "{'type': 37, 'word': ['text', 'prompt', 'prompts'], 'time': '2/23', 'size': 78.27890000000001, 'pmi_baseline': 7.27903205257864}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'bard', 'azure', 'chatgpt3', 'msft', 'gpt4', 'whisper', 'apis'], 'time': '2/26', 'size': 2030.3831999999984, 'pmi_baseline': 6.238489024221857}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '2/26', 'size': 561.6650999999999, 'pmi_baseline': 6.314997742357969}\n",
      "{'type': 40, 'word': ['musk', 'elon'], 'time': '2/26', 'size': 111.95159999999998, 'pmi_baseline': 10.754945176470622}\n",
      "{'type': 41, 'word': ['elonmusk', 'altcoin', 'altcoins', 'https', 'vr'], 'time': '2/26', 'size': 174.95340000000004, 'pmi_baseline': 7.286835074011364}\n",
      "{'type': 42, 'word': ['crypto', 'metaverse', 'cryptocurrency', 'web3', 'bitcoin'], 'time': '2/26', 'size': 172.21259999999998, 'pmi_baseline': 7.880798510648667}\n",
      "{'type': 43, 'word': ['twitter', 'linkedin', 'podcast'], 'time': '2/26', 'size': 85.0437, 'pmi_baseline': 6.234034465571584}\n",
      "{'type': 44, 'word': ['prompts', 'code', 'prompt', 'resume'], 'time': '2/26', 'size': 79.74880000000002, 'pmi_baseline': 5.90161521372221}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4', 'nlp'], 'time': '3/1', 'size': 2630.0507999999995, 'pmi_baseline': 6.293824450392355}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/1', 'size': 725.0462999999997, 'pmi_baseline': 6.314997742357969}\n",
      "{'type': 45, 'word': ['artificialintelligence', 'elonmusk', 'vr'], 'time': '3/1', 'size': 371.4291, 'pmi_baseline': 3.8334967198126932}\n",
      "{'type': 46, 'word': ['trading', 'metaverse', 'crypto', 'tech'], 'time': '3/1', 'size': 296.78310000000005, 'pmi_baseline': 5.483400540394292}\n",
      "{'type': 47, 'word': ['prompts', 'resume'], 'time': '3/1', 'size': 132.11219999999997, 'pmi_baseline': 0}\n",
      "{'type': 48, 'word': ['seo', 'marketing', 'copywriting'], 'time': '3/1', 'size': 140.0906, 'pmi_baseline': 8.430867941764644}\n",
      "{'type': 41, 'word': ['elonmusk', 'elon', 'altcoins', 'musk', 'altcoin', 'https'], 'time': '3/1', 'size': 82.23430000000002, 'pmi_baseline': 7.7931880919227075}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4', 'slack', 'ceo'], 'time': '3/4', 'size': 1654.7122000000008, 'pmi_baseline': 6.293824450392355}\n",
      "{'type': 49, 'word': ['chatbot', 'bot', 'robot', 'intelligence', 'app'], 'time': '3/4', 'size': 376.99890000000005, 'pmi_baseline': 6.070063398673309}\n",
      "{'type': 45, 'word': ['artificialintelligence', 'elonmusk', 'elon', 'vr', 'musk', 'ceo'], 'time': '3/4', 'size': 289.85869999999994, 'pmi_baseline': 6.937788177611473}\n",
      "{'type': 1, 'word': ['technology', 'intelligence', 'chatbot', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/4', 'size': 227.2812, 'pmi_baseline': 6.314997742357969}\n",
      "{'type': 50, 'word': ['upsc', 'exam'], 'time': '3/4', 'size': 104.91070000000005, 'pmi_baseline': 10.032344248026183}\n",
      "{'type': 51, 'word': ['resume', 'prompts', 'tweet'], 'time': '3/4', 'size': 127.72639999999996, 'pmi_baseline': 4.985474748692206}\n",
      "{'type': 52, 'word': ['metaverse', 'crypto', 'nft'], 'time': '3/4', 'size': 137.66120000000006, 'pmi_baseline': 7.468149750740324}\n",
      "{'type': 53, 'word': ['chatgpt3', 'nlp'], 'time': '3/4', 'size': 50.15369999999999, 'pmi_baseline': 0}\n",
      "{'type': 54, 'word': ['marketing', 'business'], 'time': '3/4', 'size': 47.95389999999999, 'pmi_baseline': 5.80315157395992}\n",
      "{'type': 41, 'word': ['elonmusk', 'elon', 'altcoins', 'musk', 'altcoin', 'https', 'ceo'], 'time': '3/4', 'size': 44.3973, 'pmi_baseline': 7.7931880919227075}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4'], 'time': '3/7', 'size': 1980.0892000000013}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/7', 'size': 700.6083}\n",
      "{'type': 55, 'word': ['artificialintelligence', 'chomsky', 'westworld', 'chatgpt3', 'southpark'], 'time': '3/7', 'size': 339.86550000000005}\n",
      "{'type': 56, 'word': ['prompts', 'prompt'], 'time': '3/7', 'size': 82.9571}\n",
      "{'type': 57, 'word': ['blog', 'podcast'], 'time': '3/7', 'size': 50.49119999999999}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4'], 'time': '3/10', 'size': 1660.0196}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/10', 'size': 279.1637}\n",
      "{'type': 55, 'word': ['westworld', 'artificialintelligence', 'chatgpt3', 'chatgpt4', 'southpark', 'chomsky'], 'time': '3/10', 'size': 351.8026999999999}\n",
      "{'type': 58, 'word': ['episode', 'podcast'], 'time': '3/10', 'size': 49.624300000000005}\n",
      "{'type': 59, 'word': ['prompts', 'prompt', 'text'], 'time': '3/10', 'size': 66.90670000000001}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'gpt4'], 'time': '3/13', 'size': 4480.077999999995}\n",
      "{'type': 60, 'word': ['chatgpt4', 'chatgpt3', 'elonmusk', 'nlp'], 'time': '3/13', 'size': 585.7348999999997}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/13', 'size': 720.0681}\n",
      "{'type': 59, 'word': ['text', 'prompt', 'prompts'], 'time': '3/13', 'size': 137.4864}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'copilot', 'gpt4'], 'time': '3/16', 'size': 4035.682900000003}\n",
      "{'type': 61, 'word': ['chatgpt4', 'artificialintelligence', 'elonmusk', 'baidu', 'bitcoin', 'chatgpt3', 'doubled', 'btc'], 'time': '3/16', 'size': 977.8660999999993}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/16', 'size': 623.9029000000002}\n",
      "{'type': 62, 'word': ['crypto', 'nft'], 'time': '3/16', 'size': 154.33679999999995}\n",
      "{'type': 59, 'word': ['text', 'prompt', 'prompts'], 'time': '3/16', 'size': 99.00019999999998}\n",
      "{'type': 63, 'word': ['marketing', 'copywriter', 'business'], 'time': '3/16', 'size': 122.50589999999997}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'copilot', 'gpt4'], 'time': '3/19', 'size': 2798.754100000002}\n",
      "{'type': 61, 'word': ['baidu', 'artificialintelligence', 'chatgpt3', 'elonmusk', 'btc', 'chatgpt4', 'bitcoin', 'doubled'], 'time': '3/19', 'size': 389.82879999999983}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/19', 'size': 493.6056999999999}\n",
      "{'type': 64, 'word': ['crypto', 'bitcoin', 'nfts', 'binance', 'nft', 'stocks'], 'time': '3/19', 'size': 238.89089999999996}\n",
      "{'type': 65, 'word': ['prompts', 'prompt', 'tweet', 'code', 'text', 'tweets'], 'time': '3/19', 'size': 237.17739999999995}\n",
      "{'type': 63, 'word': ['copywriter', 'business', 'marketing'], 'time': '3/19', 'size': 58.280499999999996}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'github', 'copilot', 'gpt4'], 'time': '3/22', 'size': 3699.665200000001}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/22', 'size': 733.5094000000004}\n",
      "{'type': 61, 'word': ['baidu', 'artificialintelligence', 'chatgpt3', 'elonmusk', 'btc', 'chatgpt4', 'bitcoin', 'agi', 'doubled'], 'time': '3/22', 'size': 361.4167}\n",
      "{'type': 66, 'word': ['plugins', 'copilot', 'app', 'plugin'], 'time': '3/22', 'size': 279.36609999999996}\n",
      "{'type': 65, 'word': ['text', 'tweet', 'code', 'tweets', 'prompts', 'prompt'], 'time': '3/22', 'size': 207.9008}\n",
      "{'type': 67, 'word': ['seo', 'marketing', 'copywriting'], 'time': '3/22', 'size': 134.72000000000003}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'github', 'copilot', 'gpt4'], 'time': '3/25', 'size': 2655.4832}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/25', 'size': 233.7944}\n",
      "{'type': 68, 'word': ['chatgpt4', 'ticker', 'candle', 'agi', 'elonmusk', 'chatgpt3'], 'time': '3/25', 'size': 432.53350000000006}\n",
      "{'type': 69, 'word': ['binance', 'crypto', 'bitcoin'], 'time': '3/25', 'size': 232.4995999999999}\n",
      "{'type': 65, 'word': ['text', 'tweet', 'code', 'tweets', 'prompts', 'prompt'], 'time': '3/25', 'size': 164.1951}\n",
      "{'type': 66, 'word': ['app', 'copilot', 'plugins', 'plugin'], 'time': '3/25', 'size': 103.95190000000002}\n",
      "{'type': 70, 'word': ['writing', 'programming'], 'time': '3/25', 'size': 80.65520000000001}\n",
      "{'type': 0, 'word': ['bot', 'ai', 'app', 'apis', 'snapchat', 'bing', 'google', 'api', 'microsoft', 'openai', 'robot', 'siri', 'agi', 'gpt3', 'china', 'search', 'twitter', 'slack', 'bard', 'azure', 'chatgpt3', 'msft', 'whisper', 'github', 'copilot', 'gpt4'], 'time': '3/28', 'size': 2707.130699999999}\n",
      "{'type': 1, 'word': ['technology', 'bot', 'multimodal', 'intelligence', 'chatbot', 'app', 'robots', 'generative', 'chatbots', 'conversational', 'language'], 'time': '3/28', 'size': 453.065}\n",
      "{'type': 68, 'word': ['ticker', 'candle', 'chatgpt3', 'elonmusk', 'doge', 'chatgpt4', 'elon', 'musk', 'agi'], 'time': '3/28', 'size': 251.92799999999994}\n",
      "{'type': 65, 'word': ['text', 'tweet', 'code', 'tweets', 'prompts', 'prompt'], 'time': '3/28', 'size': 111.7335}\n",
      "{'type': 66, 'word': ['app', 'copilot', 'plugins', 'plugin'], 'time': '3/28', 'size': 58.892800000000015}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for topics_day in list_exist_all_topics:\n",
    "    for topic in topics_day:\n",
    "        print(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
